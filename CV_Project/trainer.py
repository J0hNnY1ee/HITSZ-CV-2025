# trainer.py

import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np # ç”¨äºæŒ‡æ ‡æ ¼å¼åŒ–

from utils import save_checkpoint # load_checkpoint é€šå¸¸åœ¨ main.py ä¸­ä½¿ç”¨
from evaluate import evaluate_segmentation

class Trainer:
    def __init__(self,
                 model: nn.Module,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 criterion: nn.Module,
                 optimizer: optim.Optimizer,
                 scheduler: optim.lr_scheduler._LRScheduler = None,
                 device: torch.device = None,
                 num_epochs: int = 100,
                 num_classes_eval: int = -1,
                 ignore_index_eval: int = -1,
                 experiment_dir: str = "experiment_outputs", # å®éªŒè¾“å‡ºæ ¹ç›®å½•
                 checkpoint_prefix: str = "model_ckpt",
                 start_epoch: int = 0,
                 best_metric_val: float = float('-inf'),
                 metric_to_optimize: str = 'mean_iou',
                 print_freq: int = 10,
                 save_summary_writer = None
                 ):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.scheduler = scheduler

        if device is None:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = device
        self.model.to(self.device)

        self.num_epochs = num_epochs
        self.num_classes_eval = num_classes_eval
        self.ignore_index_eval = ignore_index_eval
        self.experiment_dir = experiment_dir # æ‰€æœ‰è¾“å‡ºéƒ½åˆ°è¿™é‡Œ
        self.checkpoint_prefix = checkpoint_prefix
        self.start_epoch = start_epoch
        self.current_epoch = start_epoch
        self.best_metric_val = best_metric_val
        self.metric_to_optimize = metric_to_optimize
        self.print_freq = print_freq
        self.summary_writer = save_summary_writer

        # è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.training_log_file = os.path.join(self.experiment_dir, "training_log.txt")
        self._log_message(f"Trainer åˆå§‹åŒ–å®Œæˆ:", console_too=False) # é¿å…é‡å¤æ‰“å°
        self._log_message(f"  è®¾å¤‡: {self.device}", console_too=False)
        self._log_message(f"  æ€»è®­ç»ƒè½®æ•°: {self.num_epochs}", console_too=False)
        self._log_message(f"  å°†ä» Epoch {self.start_epoch} å¼€å§‹è®­ç»ƒ", console_too=False)
        self._log_message(f"  å½“å‰æœ€ä½³ {self.metric_to_optimize}: {self.best_metric_val:.4f}", console_too=False)
        self._log_message(f"  è¯„ä¼°æ—¶ç±»åˆ«æ•°: {self.num_classes_eval}", console_too=False)
        self._log_message(f"  è¯„ä¼°æ—¶å¿½ç•¥ç´¢å¼•: {self.ignore_index_eval}", console_too=False)
        self._log_message(f"  å®éªŒè¾“å‡ºç›®å½•: {self.experiment_dir}", console_too=False)


    def _log_message(self, message: str, console_too: bool = True):
        """è®°å½•æ¶ˆæ¯åˆ°æ—¥å¿—æ–‡ä»¶å’Œæ§åˆ¶å°ã€‚"""
        if console_too:
            print(message)
        try:
            with open(self.training_log_file, 'a') as f:
                f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}\n")
        except Exception as e:
            print(f"å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")


    def train_one_epoch(self):
        self.model.train()
        total_loss = 0.0
        num_samples = 0
        progress_bar = tqdm(self.train_loader, desc=f"Epoch {self.current_epoch + 1}/{self.num_epochs} [è®­ç»ƒä¸­]", leave=False)

        for batch_idx, (images, targets) in enumerate(progress_bar):
            images = images.to(self.device)
            targets = targets.to(self.device)
            self.optimizer.zero_grad()
            outputs = self.model(images)
            loss = self.criterion(outputs, targets)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item() * images.size(0)
            num_samples += images.size(0)

            if (batch_idx + 1) % self.print_freq == 0 or (batch_idx + 1) == len(self.train_loader):
                current_lr = self.optimizer.param_groups[0]['lr']
                progress_bar.set_postfix({
                    'Loss': f"{loss.item():.4f}",
                    'AvgLoss': f"{total_loss / num_samples:.4f}",
                    'LR': f"{current_lr:.1e}"
                })
                if self.summary_writer:
                    step = self.current_epoch * len(self.train_loader) + batch_idx
                    self.summary_writer.add_scalar('Train/Batch_Loss', loss.item(), step)
                    self.summary_writer.add_scalar('Train/Learning_Rate', current_lr, step)

        avg_train_loss = total_loss / num_samples
        progress_bar.close()
        log_msg = f"Epoch {self.current_epoch + 1}/{self.num_epochs} [è®­ç»ƒç»“æŸ] - å¹³å‡è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}"
        self._log_message(log_msg)

        if self.summary_writer:
            self.summary_writer.add_scalar('Train/Epoch_Loss', avg_train_loss, self.current_epoch + 1)
        return avg_train_loss


    def validate(self):
        self._log_message(f"Epoch {self.current_epoch + 1}/{self.num_epochs} [éªŒè¯ä¸­]...")
        avg_val_loss, metrics = evaluate_segmentation(
            self.model, self.val_loader, self.criterion, self.device,
            num_classes=self.num_classes_eval, ignore_index=self.ignore_index_eval
        )

        self._log_message(f"Epoch {self.current_epoch + 1}/{self.num_epochs} [éªŒè¯ç»“æŸ] - å¹³å‡éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
        self._log_message(f"  éªŒè¯æŒ‡æ ‡:")
        for k, v in metrics.items():
            if isinstance(v, (float, np.float32, np.float64)): # np.float64 is for numpy scalars
                 self._log_message(f"    {k}: {v:.4f}", console_too=False) # é¿å…é‡å¤æ‰“å°åˆ°æ§åˆ¶å°
            elif isinstance(v, np.ndarray) and k.endswith('_per_class'):
                self._log_message(f"    {k}: {np.round(v, 4).tolist()}", console_too=False)


        if self.summary_writer:
            self.summary_writer.add_scalar('Val/Epoch_Loss', avg_val_loss, self.current_epoch + 1)
            for k, v in metrics.items():
                if isinstance(v, (float, np.float32, np.float64)):
                    self.summary_writer.add_scalar(f'Val/{k}', v, self.current_epoch + 1)
        return avg_val_loss, metrics


    def run_training(self):
        self._log_message(f"\n{'='*20} å¼€å§‹è®­ç»ƒ {'='*20}", console_too=False) # mainä¸­å·²æ‰“å°
        self._log_message(f"æ¨¡å‹å°†è®­ç»ƒ {self.num_epochs - self.start_epoch} ä¸ªè½®æ¬¡ (ä» epoch {self.start_epoch+1} åˆ° {self.num_epochs})", console_too=False)

        for epoch in range(self.start_epoch, self.num_epochs):
            self.current_epoch = epoch
            epoch_start_time = time.time()
            _ = self.train_one_epoch()
            avg_val_loss, val_metrics = self.validate()

            if self.scheduler:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    metric_for_scheduler = avg_val_loss if self.metric_to_optimize.lower().endswith('loss') \
                                           else val_metrics.get(self.metric_to_optimize, float('-inf'))
                    self.scheduler.step(metric_for_scheduler)
                else:
                    self.scheduler.step()

            current_metric_val = val_metrics.get(self.metric_to_optimize)
            if current_metric_val is None:
                self._log_message(f"è­¦å‘Š: æ— æ³•åœ¨éªŒè¯æŒ‡æ ‡ä¸­æ‰¾åˆ° '{self.metric_to_optimize}'ã€‚å°†ä½¿ç”¨éªŒè¯æŸå¤±çš„è´Ÿå€¼è¿›è¡Œæ¯”è¾ƒã€‚")
                current_metric_val = -avg_val_loss
                is_best = current_metric_val > self.best_metric_val
            else:
                is_best = current_metric_val > self.best_metric_val

            if is_best:
                self.best_metric_val = current_metric_val
                self._log_message(f"  ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! {self.metric_to_optimize}: {self.best_metric_val:.4f} at epoch {self.current_epoch + 1}")

            checkpoint_state = {
                'epoch': self.current_epoch + 1,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'best_metric_val': self.best_metric_val,
                'metric_name': self.metric_to_optimize
            }
            if self.scheduler:
                checkpoint_state['scheduler_state_dict'] = self.scheduler.state_dict()

            # ä¿å­˜æ£€æŸ¥ç‚¹åˆ°å®éªŒç›®å½•
            save_checkpoint(checkpoint_state, is_best, self.experiment_dir, self.checkpoint_prefix)
            self._log_message(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜ (Epoch {self.current_epoch + 1}, IsBest: {is_best})", console_too=False)


            epoch_duration = time.time() - epoch_start_time
            self._log_message(f"Epoch {self.current_epoch + 1} å®Œæˆï¼Œç”¨æ—¶: {epoch_duration:.2f} ç§’")
            self._log_message(f"  å½“å‰å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.1e}")
            self._log_message(f"  å½“å‰æœ€ä½³ {self.metric_to_optimize}: {self.best_metric_val:.4f}")
            self._log_message("-" * 50, console_too=False)


        self._log_message(f"\n{'='*20} è®­ç»ƒå®Œæˆ {'='*20}")
        self._log_message(f"æœ€ä½³ {self.metric_to_optimize} åœ¨éªŒè¯é›†ä¸Šè¾¾åˆ°: {self.best_metric_val:.4f}")
        if self.summary_writer:
            self.summary_writer.close()