{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c739c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.ipynb\n",
    "\n",
    "# 基本库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 从我们自己创建的 .py 文件中导入\n",
    "# 确保 dataset.py, model.py, trainer.py 与此 notebook 在同一目录下\n",
    "# 或者它们所在的目录在 Python 的搜索路径中\n",
    "try:\n",
    "    import dataset\n",
    "    import model\n",
    "    import trainer\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing local modules: {e}\")\n",
    "    print(\"Please ensure dataset.py, model.py, and trainer.py are in the same directory or in PYTHONPATH.\")\n",
    "    # 在Colab等环境中，如果文件在驱动器，可能需要挂载驱动器并添加到sys.path\n",
    "    # import sys\n",
    "    # sys.path.append('/content/drive/My Drive/your_project_folder') # 示例\n",
    "    # import dataset, model, trainer \n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 设置随机种子以便结果可复现 (可选)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED) # if you are using multi-GPU.\n",
    "    # CuDNN的确定性设置，可能会影响性能，但有助于复现\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # 设置为 False 以获得完全的确定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e85b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 配置参数 ---\n",
    "\n",
    "# 数据集参数\n",
    "DATA_ROOT = './data_voc' # PASCAL VOC 数据集下载/存放的根目录\n",
    "IMG_HEIGHT = dataset.IMG_HEIGHT # 使用 dataset.py 中定义的默认值 (256)\n",
    "IMG_WIDTH = dataset.IMG_WIDTH   # (256)\n",
    "NUM_CLASSES = dataset.NUM_CLASSES # (21)\n",
    "\n",
    "# 模型参数\n",
    "# 我们使用的是 SimpleFCN，它会从 dataset.py 获取 NUM_CLASSES\n",
    "# 如果需要，可以在这里指定要加载的预训练模型路径等\n",
    "\n",
    "# 训练参数\n",
    "BATCH_SIZE = 8      # 根据你的GPU显存调整\n",
    "NUM_EPOCHS = 25     # 训练的总轮数 (可以先设小一点测试，比如5-10轮)\n",
    "LEARNING_RATE = 1e-4 # 学习率\n",
    "WEIGHT_DECAY = 1e-5  # 优化器的权重衰减 (L2正则化)\n",
    "OPTIMIZER_TYPE = 'Adam' # 'Adam' or 'SGD'\n",
    "SCHEDULER_TYPE = 'StepLR' # 'StepLR', 'ReduceLROnPlateau', or None\n",
    "STEP_LR_STEP_SIZE = 10 # For StepLR: 每 N 个 epochs 降低学习率\n",
    "STEP_LR_GAMMA = 0.1    # For StepLR: 学习率降低的倍数\n",
    "\n",
    "# 文件路径\n",
    "MODEL_SAVE_DIR = './saved_models'\n",
    "BEST_MODEL_NAME = 'best_fcn_voc.pth'\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, BEST_MODEL_NAME)\n",
    "\n",
    "# 其他\n",
    "NUM_WORKERS = 2 # DataLoader 的工作进程数\n",
    "DOWNLOAD_DATA = True # 第一次运行时设为True，之后可以设为False如果数据已下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading PASCAL VOC 2012 dataset...\")\n",
    "train_loader, val_loader = dataset.get_dataloaders(\n",
    "    data_root=DATA_ROOT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    img_height=IMG_HEIGHT,\n",
    "    img_width=IMG_WIDTH,\n",
    "    download_data=DOWNLOAD_DATA\n",
    ")\n",
    "\n",
    "if train_loader and val_loader:\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    # 可视化一个训练样本 (可选)\n",
    "    print(\"\\nVisualizing a sample from training data...\")\n",
    "    try:\n",
    "        sample_images, sample_masks = next(iter(train_loader))\n",
    "        img_pil = dataset.tensor_to_pil(sample_images[0])\n",
    "        mask_pil = dataset.mask_to_pil_color(sample_masks[0])\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(img_pil)\n",
    "        axes[0].set_title(\"Sample Image\")\n",
    "        axes[0].axis('off')\n",
    "        axes[1].imshow(mask_pil)\n",
    "        axes[1].set_title(\"Sample Ground Truth Mask\")\n",
    "        axes[1].axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during sample visualization: {e}\")\n",
    "else:\n",
    "    print(\"Failed to load dataloaders. Please check dataset path and download status.\")\n",
    "    # 强行停止Notebook执行，因为没有数据无法继续\n",
    "    raise RuntimeError(\"Data loading failed. Exiting notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afe023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "print(f\"Initializing model: SimpleFCN with {NUM_CLASSES} classes\")\n",
    "seg_model = model.SimpleFCN(num_classes=NUM_CLASSES, init_weights=True).to(device)\n",
    "\n",
    "# 打印模型结构和参数量 (可选)\n",
    "# print(seg_model)\n",
    "total_params = sum(p.numel() for p in seg_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in seg_model.parameters() if p.requires_grad)\n",
    "print(f\"Total model parameters: {total_params:,}\")\n",
    "print(f\"Trainable model parameters: {trainable_params:,}\")\n",
    "\n",
    "# 定义损失函数\n",
    "# PASCAL VOC 的掩码中，我们将边界值255映射到了背景类0\n",
    "# 所以类别索引是 0 到 NUM_CLASSES-1\n",
    "# CrossEntropyLoss 默认会忽略 target 中值为 ignore_index 的像素\n",
    "# 如果我们的 dataset.py 中没有将255映射到0，这里可以设置 ignore_index=255\n",
    "# 但由于我们已经处理了，所以不需要 ignore_index\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "print(f\"Using loss function: {criterion.__class__.__name__}\")\n",
    "\n",
    "# 定义优化器\n",
    "if OPTIMIZER_TYPE.lower() == 'adam':\n",
    "    optimizer = optim.Adam(seg_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "elif OPTIMIZER_TYPE.lower() == 'sgd':\n",
    "    optimizer = optim.SGD(seg_model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported optimizer type: {OPTIMIZER_TYPE}\")\n",
    "print(f\"Using optimizer: {optimizer.__class__.__name__} with LR={LEARNING_RATE}\")\n",
    "\n",
    "# 定义学习率调度器 (可选)\n",
    "scheduler = None\n",
    "if SCHEDULER_TYPE:\n",
    "    if SCHEDULER_TYPE.lower() == 'steplr':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_LR_STEP_SIZE, gamma=STEP_LR_GAMMA)\n",
    "        print(f\"Using StepLR scheduler: step_size={STEP_LR_STEP_SIZE}, gamma={STEP_LR_GAMMA}\")\n",
    "    elif SCHEDULER_TYPE.lower() == 'reducelronplateau':\n",
    "        # 通常基于验证集指标，比如验证集损失或MIoU\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
    "        print(f\"Using ReduceLROnPlateau scheduler (monitors val MIoU).\")\n",
    "    else:\n",
    "        print(f\"Scheduler type '{SCHEDULER_TYPE}' not recognized or None. No scheduler will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化训练器\n",
    "segmentation_trainer = trainer.SemanticSegmenterTrainer(\n",
    "    model=seg_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler, # Pass the scheduler here\n",
    "    device=device,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "segmentation_trainer.train(num_epochs=NUM_EPOCHS, model_save_path_best=BEST_MODEL_PATH)\n",
    "print(\"--- Training Finished ---\")\n",
    "\n",
    "# 绘制训练过程中的损失曲线 (可选)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(segmentation_trainer.train_losses, label='Train Loss')\n",
    "plt.plot(segmentation_trainer.val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# 绘制验证集上的MIoU变化 (可选)\n",
    "if segmentation_trainer.val_metrics_history:\n",
    "    val_mious = [m['MeanIoU'] for m in segmentation_trainer.val_metrics_history]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_mious, label='Validation MIoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MIoU')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Mean IoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估训练好的最佳模型\n",
    "# trainer.evaluate() 会自动加载在训练过程中保存的最佳模型 (如果model_save_path_best被正确更新)\n",
    "# 或者我们可以明确指定要加载的模型路径\n",
    "print(\"\\n--- Evaluating Best Model on Validation Set ---\")\n",
    "\n",
    "# 确保我们的模型实例 (seg_model) 加载了最佳权重\n",
    "# trainer.train() 结束时，如果找到了最佳模型，会加载它。\n",
    "# 如果想更明确，可以重新实例化模型并加载：\n",
    "# best_seg_model = model.SimpleFCN(num_classes=NUM_CLASSES).to(device)\n",
    "# best_seg_model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "# evaluation_trainer = trainer.SemanticSegmenterTrainer(model=best_seg_model, ...) # 或者直接用现有的 segmentation_trainer\n",
    "# segmentation_trainer.model = best_seg_model # 更新trainer中的模型\n",
    "\n",
    "# 使用之前训练结束时 trainer 实例中的模型 (它应该已经加载了最佳权重)\n",
    "# 或者，如果你想确保从文件加载：\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f\"Loading best model weights from: {BEST_MODEL_PATH}\")\n",
    "    segmentation_trainer.model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "else:\n",
    "    print(f\"Warning: Best model path {BEST_MODEL_PATH} not found. Evaluating with current model weights.\")\n",
    "\n",
    "\n",
    "# 在验证集上进行评估\n",
    "# 注意: PASCAL VOC 2012 没有官方的隐藏测试集，通常做法是在 'val' 集上报告结果。\n",
    "# 如果你有单独的测试集，可以创建一个对应的 DataLoader 传给 evaluate 方法。\n",
    "val_metrics, val_confusion_matrix, val_viz_samples = segmentation_trainer.evaluate(\n",
    "    data_loader=val_loader, \n",
    "    checkpoint_path=None # 因为我们已经在上面加载了最佳模型，或 trainer 内部已经加载\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Validation MIoU: {val_metrics.get('MeanIoU', 'N/A'):.4f}\")\n",
    "\n",
    "# (可选) 打印混淆矩阵\n",
    "# print(\"\\nValidation Confusion Matrix:\")\n",
    "# print(val_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化来自评估过程的一些样本预测结果\n",
    "print(\"\\n--- Visualizing Evaluation Samples ---\")\n",
    "eval_images, eval_gt_masks, eval_pred_masks = val_viz_samples\n",
    "\n",
    "# 使用 dataset.py 中的 VOC_COLORMAP 和 VOC_CLASSES\n",
    "voc_colormap_torch = dataset.voc_colormap_to_tensor(dataset.VOC_COLORMAP).to(device)\n",
    "\n",
    "num_samples_to_show = min(len(eval_images), 5) # 最多显示5个\n",
    "\n",
    "if num_samples_to_show > 0:\n",
    "    fig, axes = plt.subplots(num_samples_to_show, 3, figsize=(12, num_samples_to_show * 4))\n",
    "    if num_samples_to_show == 1: # 如果只有一个样本，axes不是数组\n",
    "        axes = [axes] \n",
    "        \n",
    "    for i in range(num_samples_to_show):\n",
    "        img_pil = dataset.tensor_to_pil(eval_images[i])\n",
    "        gt_mask_pil = dataset.mask_to_pil_color(eval_gt_masks[i], colormap=dataset.VOC_COLORMAP)\n",
    "        pred_mask_pil = dataset.mask_to_pil_color(eval_pred_masks[i], colormap=dataset.VOC_COLORMAP) # pred_masks已经是类别索引了\n",
    "\n",
    "        axes[i][0].imshow(img_pil)\n",
    "        axes[i][0].set_title(f\"Image {i+1}\")\n",
    "        axes[i][0].axis('off')\n",
    "\n",
    "        axes[i][1].imshow(gt_mask_pil)\n",
    "        axes[i][1].set_title(f\"Ground Truth {i+1}\")\n",
    "        axes[i][1].axis('off')\n",
    "\n",
    "        axes[i][2].imshow(pred_mask_pil)\n",
    "        axes[i][2].set_title(f\"Prediction {i+1}\")\n",
    "        axes[i][2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No samples available for visualization from evaluation.\")\n",
    "\n",
    "print(\"\\n--- End of Notebook ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
