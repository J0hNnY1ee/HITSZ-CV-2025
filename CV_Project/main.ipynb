{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34769690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.ipynb\n",
    "\n",
    "# 基础和PyTorch库导入\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # 引入numpy\n",
    "\n",
    "# 导入自定义模块\n",
    "import config\n",
    "from model import UNet \n",
    "from dataset import CamVidDataset, get_class_rgb_values, image_transforms, mask_transforms_for_resize\n",
    "from trainer import  Trainer, evaluate_model \n",
    "from utils import plot_segmentation_results, CLASS_COLORMAP, NUM_CLASSES, CLASS_NAMES, pixel_accuracy, calculate_miou_and_iou_per_class\n",
    "\n",
    "\n",
    "# 1. 检查设备\n",
    "print(f\"使用设备: {config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 加载类别信息\n",
    "\n",
    "# NUM_CLASSES 和 CLASS_COLORMAP 会从 utils.py 中通过 CLASS_CSV_PATH 自动加载\n",
    "# CLASS_NAMES 也应该从 utils.py 导入，如果它在那里被定义和导出的话\n",
    "print(f\"从 utils.py 加载的信息:\")\n",
    "print(f\"  数据集共有 {NUM_CLASSES} 个类别.\")\n",
    "if CLASS_NAMES:\n",
    "    print(f\"  类别名称示例 (来自utils): {CLASS_NAMES[:5]}\")\n",
    "else:\n",
    "    print(\"  CLASS_NAMES 未从 utils.py 加载。\")\n",
    "\n",
    "# get_class_rgb_values 用于 Dataset 初始化时显式传递rgb值\n",
    "# 这个函数是从 dataset.py 导入的\n",
    "class_rgb_values_for_dataset, class_names_from_dataset = get_class_rgb_values()\n",
    "\n",
    "if not class_rgb_values_for_dataset:\n",
    "    print(\"错误: 无法从 dataset.py 的 get_class_rgb_values 加载类别RGB值。请检查 CSV 文件和路径。\")\n",
    "    CAN_PROCEED = False\n",
    "else:\n",
    "    print(f\"\\n从 dataset.py 的 get_class_rgb_values 加载的信息:\")\n",
    "    print(f\"  获取到 {len(class_names_from_dataset)} 个类别名称: {class_names_from_dataset[:5]}...\")\n",
    "    CAN_PROCEED = True\n",
    "\n",
    "# 确保 utils 和 dataset 加载的类别数量一致\n",
    "if NUM_CLASSES != len(class_rgb_values_for_dataset) and CAN_PROCEED:\n",
    "    print(f\"警告: utils.py (NUM_CLASSES={NUM_CLASSES}) 和 dataset.py (len={len(class_rgb_values_for_dataset)}) 的类别数量不一致!\")\n",
    "    # 可以选择在这里设置 CAN_PROCEED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978063fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 准备数据集\n",
    "if CAN_PROCEED:\n",
    "    print(\"准备数据集...\")\n",
    "    try:\n",
    "        train_dataset = CamVidDataset(\n",
    "            image_dir=os.path.join(config.DATA_DIR, 'train'),\n",
    "            mask_dir=os.path.join(config.DATA_DIR, 'train_labels'),\n",
    "            class_rgb_values=class_rgb_values_for_dataset, # 使用从 dataset.py 加载的值\n",
    "            transform=image_transforms,\n",
    "            mask_transform=mask_transforms_for_resize\n",
    "        )\n",
    "\n",
    "        val_dataset = CamVidDataset(\n",
    "            image_dir=os.path.join(config.DATA_DIR, 'val'),\n",
    "            mask_dir=os.path.join(config.DATA_DIR, 'val_labels'),\n",
    "            class_rgb_values=class_rgb_values_for_dataset, # 使用从 dataset.py 加载的值\n",
    "            transform=image_transforms,\n",
    "            mask_transform=mask_transforms_for_resize\n",
    "        )\n",
    "\n",
    "        print(f\"训练集样本数: {len(train_dataset)}\")\n",
    "        print(f\"验证集样本数: {len(val_dataset)}\")\n",
    "\n",
    "        # 可选：测试一个样本\n",
    "        if len(train_dataset) > 0:\n",
    "            # 尝试获取一个有效样本\n",
    "            idx_to_try = 0\n",
    "            img_sample, mask_sample = None, None\n",
    "            while idx_to_try < len(train_dataset):\n",
    "                img_sample, mask_sample = train_dataset[idx_to_try]\n",
    "                if img_sample is not None and mask_sample is not None:\n",
    "                    break\n",
    "                idx_to_try += 1\n",
    "            \n",
    "            if img_sample is not None:\n",
    "                print(f\"从训练集获取的图像尺寸: {img_sample.shape}, 掩码尺寸: {mask_sample.shape}, 掩码数据类型: {mask_sample.dtype}\")\n",
    "            else:\n",
    "                print(\"无法从训练集获取任何有效样本。\")\n",
    "                CAN_PROCEED = False\n",
    "        elif len(train_dataset) == 0 : # 如果数据集本身长度为0\n",
    "             print(\"训练集为空，无法继续。\")\n",
    "             CAN_PROCEED = False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"创建数据集时发生错误: {e}\")\n",
    "        CAN_PROCEED = False\n",
    "else:\n",
    "    print(\"由于类别信息加载失败，跳过数据集准备。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119df446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 准备DataLoaders\n",
    "\n",
    "if CAN_PROCEED:\n",
    "    # 处理Dataset中 __getitem__ 可能返回 (None, None) 的情况\n",
    "    def collate_fn(batch):\n",
    "        # 过滤掉那些 __getitem__ 返回 (None, None) 的项\n",
    "        # batch 是一个列表，每个元素是 (image_tensor, mask_tensor) 或 (None, None)\n",
    "        batch = list(filter(lambda x: x is not None and x[0] is not None and x[1] is not None, batch))\n",
    "        if not batch: # 如果过滤后批次为空\n",
    "            return None, None # Trainer需要能处理这种情况\n",
    "        return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True if config.DEVICE == \"cuda\" else False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True if config.DEVICE == \"cuda\" else False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    print(f\"训练 DataLoader 批次数 (估计): {len(train_dataset) // config.BATCH_SIZE}\") # 实际长度取决于collate_fn\n",
    "    print(f\"验证 DataLoader 批次数 (估计): {len(val_dataset) // config.BATCH_SIZE}\")\n",
    "\n",
    "    # 检查DataLoader是否能产生数据 (更可靠的检查)\n",
    "    try:\n",
    "        train_batch_img, train_batch_mask = next(iter(train_loader))\n",
    "        if train_batch_img is None:\n",
    "            print(\"错误：训练DataLoader返回了空批次。请检查数据集和collate_fn。\")\n",
    "            CAN_PROCEED = False\n",
    "        else:\n",
    "            print(f\"成功从 train_loader 获取批次: 图像 {train_batch_img.shape}, 掩码 {train_batch_mask.shape}\")\n",
    "    except StopIteration:\n",
    "        print(\"错误：训练DataLoader为空。\")\n",
    "        CAN_PROCEED = False\n",
    "    \n",
    "    if CAN_PROCEED:\n",
    "        try:\n",
    "            val_batch_img, val_batch_mask = next(iter(val_loader))\n",
    "            if val_batch_img is None:\n",
    "                print(\"错误：验证DataLoader返回了空批次。\")\n",
    "                CAN_PROCEED = False\n",
    "            else:\n",
    "                print(f\"成功从 val_loader 获取批次: 图像 {val_batch_img.shape}, 掩码 {val_batch_mask.shape}\")\n",
    "        except StopIteration:\n",
    "            print(\"错误：验证DataLoader为空。\")\n",
    "            CAN_PROCEED = False\n",
    "            \n",
    "    if CAN_PROCEED:\n",
    "        print(\"DataLoaders准备就绪。\")\n",
    "\n",
    "else:\n",
    "    print(\"由于数据集准备失败，跳过DataLoader准备。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 初始化模型\n",
    "if CAN_PROCEED:\n",
    "    print(\"初始化模型...\")\n",
    "    # NUM_CLASSES 是从 utils.py 导入的 (应与dataset.py中的一致)\n",
    "    model = model = UNet(n_channels=3, n_classes=NUM_CLASSES)\n",
    "    print(model) # 打印模型结构\n",
    "    # 将模型移到设备\n",
    "    model.to(config.DEVICE)\n",
    "else:\n",
    "    print(\"由于前期步骤失败，跳过模型初始化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 初始化训练器并开始训练\n",
    "if CAN_PROCEED:\n",
    "    print(\"初始化训练器...\")\n",
    "    # 确保 trainer.py 中的 Trainer 类可以处理 DataLoader 返回 (None, None) 的情况\n",
    "    # 或者确保 collate_fn 不会轻易让这种事情发生给 Trainer\n",
    "    trainer = Trainer(model, train_loader, val_loader, num_classes=NUM_CLASSES, device=config.DEVICE)\n",
    "\n",
    "    print(\"开始训练...\")\n",
    "    # trainer.fit() 应该返回这些列表\n",
    "    train_losses, val_losses, val_accuracies = trainer.fit(config.NUM_EPOCHS)\n",
    "else:\n",
    "    print(\"由于前期步骤失败，跳过训练。\")\n",
    "    # 定义空列表以便后续单元格不会因变量未定义而报错\n",
    "    train_losses, val_losses, val_accuracies = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164af9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 绘制训练和验证损失/准确率曲线\n",
    "if CAN_PROCEED and train_losses and val_losses and val_accuracies: # 确保训练已进行且有数据可画\n",
    "    plt.figure(figsize=(12, 5)) # 设置图表大小\n",
    "\n",
    "    # 第一个子图：损失曲线\n",
    "    plt.subplot(1, 2, 1) # 定义第一个子图 (1行2列中的第1个)\n",
    "    plt.plot(train_losses, label='Training Loss') # 绘制训练损失曲线\n",
    "    plt.plot(val_losses, label='Validation Loss') # 绘制验证损失曲线\n",
    "    plt.xlabel('Epochs') # 设置X轴标签\n",
    "    plt.ylabel('Loss')   # 设置Y轴标签\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curves') # 设置图像标题\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 第二个子图：验证准确率曲线\n",
    "    plt.subplot(1, 2, 2) # 定义第二个子图 (1行2列中的第2个)\n",
    "    plt.plot(val_accuracies, label='Validation Pixel Accuracy', color='green') # 绘制验证准确率曲线\n",
    "    plt.xlabel('Epochs') # 设置X轴标签\n",
    "    plt.ylabel('Accuracy') # 设置Y轴标签\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy Curve') # 设置图像标题\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout() # 自动调整子图布局，避免重叠\n",
    "    plt.show()\n",
    "elif CAN_PROCEED:\n",
    "    # 这部分 print 语句保留中文，因为它们不是图片上的文字，而是控制台输出\n",
    "    print(\"训练已执行，但未能获取到损失或准确率数据用于绘图。\")\n",
    "else:\n",
    "    print(\"由于前期步骤失败，没有训练数据可供绘图。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. 模型评估 (在验证集上)\n",
    "# 此单元格使用封装在 trainer.py 中的 evaluate_model 函数进行评估。\n",
    "\n",
    "# 确保 CAN_PROCEED, config.MODEL_SAVE_PATH 等条件满足\n",
    "if CAN_PROCEED and config.MODEL_SAVE_PATH and os.path.exists(config.MODEL_SAVE_PATH):\n",
    "    print(f\"\\n--- 开始模型评估 (使用封装函数) ---\")\n",
    "    print(f\"从 {config.MODEL_SAVE_PATH} 加载模型用于评估...\")\n",
    "\n",
    "    # 1. 重新初始化模型结构并加载权重\n",
    "    # NUM_CLASSES 应已从 utils.py 正确加载\n",
    "    eval_model = UNet(n_channels=3, n_classes=NUM_CLASSES)\n",
    "    try:\n",
    "        eval_model.load_state_dict(torch.load(config.MODEL_SAVE_PATH, map_location=config.DEVICE))\n",
    "        eval_model.to(config.DEVICE)\n",
    "        # model.eval() 会在 evaluate_model 函数内部调用\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型权重失败: {e}\")\n",
    "        # 如果加载失败，则无法继续评估\n",
    "        eval_model = None \n",
    "\n",
    "    # 2. 准备评估用的DataLoader (通常复用val_loader)\n",
    "    # 确保 val_loader 在当前作用域内仍然可用且非空\n",
    "    if 'val_loader' not in globals() or val_loader is None:\n",
    "        print(\"错误: val_loader 未定义或为空，无法进行评估。\")\n",
    "        print(\"请确保之前的单元格已成功运行或考虑在此处重新创建DataLoader。\")\n",
    "        current_eval_loader = None\n",
    "    else:\n",
    "        # 检查 DataLoader 是否为空 (如果所有数据都被 collate_fn 过滤掉)\n",
    "        # 一个简单的方法是尝试获取迭代器长度，但这不适用于所有 DataLoader\n",
    "        # 更安全的是让 evaluate_model 处理空的 DataLoader\n",
    "        print(\"使用已有的 val_loader 进行评估。\")\n",
    "        current_eval_loader = val_loader \n",
    "\n",
    "    if eval_model and current_eval_loader:\n",
    "        # 3. 定义评估时使用的损失函数\n",
    "        criterion_eval = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # 4. 调用封装的评估函数\n",
    "        # plot_segmentation_results 来自 utils.py (已导入)\n",
    "        # CLASS_NAMES 和 NUM_CLASSES 来自 utils.py (已导入)\n",
    "        # config.DEVICE 来自 config.py (已导入)\n",
    "        evaluate_model(\n",
    "            model=eval_model,\n",
    "            dataloader=current_eval_loader,\n",
    "            criterion=criterion_eval,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            class_names=CLASS_NAMES, # CLASS_NAMES 从 utils 导入\n",
    "            device=config.DEVICE,\n",
    "            plot_segmentation_results_func=plot_segmentation_results, # 传递绘图函数\n",
    "            num_vis_samples=min(3, config.BATCH_SIZE) # 可视化样本数，不超过3或批大小\n",
    "        )\n",
    "    elif not eval_model:\n",
    "        print(\"由于模型加载失败，跳过评估。\")\n",
    "    else: # current_eval_loader is None\n",
    "        print(\"评估加载器 (current_eval_loader) 未准备好或为空，跳过调用 evaluate_model。\")\n",
    "\n",
    "elif not CAN_PROCEED:\n",
    "    print(\"由于前期步骤失败，跳过模型评估。\")\n",
    "elif not config.MODEL_SAVE_PATH:\n",
    "    print(\"模型保存路径 (MODEL_SAVE_PATH) 未在 config.py 中定义，跳过模型评估。\")\n",
    "elif not os.path.exists(config.MODEL_SAVE_PATH):\n",
    "    print(f\"已保存的模型文件 {config.MODEL_SAVE_PATH} 未找到，跳过模型评估。\")\n",
    "else:\n",
    "    print(\"未知原因导致无法进行评估。请检查 CAN_PROCEED 状态和模型路径。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
